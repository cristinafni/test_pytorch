{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poserefine.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOPYHjUzFapCI4TQhK+9V7f"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2WxZsMAx4m7"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.7\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{torch.__version__[0:5:2]}\"\n",
        "        ])\n",
        "        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZNYpMY5x9a0"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "from skimage.color import rgb2gray\n",
        "from stl.mesh import Mesh\n",
        "\n",
        "from pytorch3d.structures import Meshes, join_meshes_as_batch\n",
        "from pytorch3d.io import load_obj\n",
        "from pytorch3d.transforms import Rotate, Translate\n",
        "from pytorch3d.renderer.materials import Materials\n",
        "from pytorch3d.renderer.mesh import TexturesVertex\n",
        "from pytorch3d.renderer.lighting import PointLights\n",
        "from pytorch3d.renderer import (\n",
        "    OpenGLPerspectiveCameras,\n",
        "    RasterizationSettings,\n",
        "    MeshRenderer,\n",
        "    MeshRasterizer,\n",
        "    BlendParams,\n",
        "    SoftSilhouetteShader,\n",
        "    HardPhongShader,\n",
        ")\n",
        "import imageio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import img_as_ubyte\n",
        "# 3D transformations functions\n",
        "from pytorch3d.transforms import Rotate, Translate\n",
        "# rendering components\n",
        "from pytorch3d.renderer import (\n",
        "    FoVPerspectiveCameras, look_at_view_transform, look_at_rotation, \n",
        "    RasterizationSettings, MeshRenderer, MeshRasterizer, BlendParams,\n",
        "    SoftSilhouetteShader, HardPhongShader, PointLights, TexturesVertex,\n",
        ")\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from rotation import rotation_matrix_from_euler\n",
        "from losses import JaccardLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEox5NaAyD0e"
      },
      "source": [
        "class Pytorch3dViewer():\n",
        "    \"\"\"creates render images from stls and poses that can be backpropagated\"\"\"\n",
        "\n",
        "    def __init__(self, img_size: int = 200, device=None):\n",
        "        if device is None:\n",
        "            self.device = torch.device(\"cuda:0\")\n",
        "        else:\n",
        "            self.device = device\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # standard values from `deepautomatch.viewer`\n",
        "        # as we are only using calibration-corrected poses here, these are the important ones\n",
        "        std_img_size = 1000 # change?\n",
        "        std_cal_mm_per_pxl = 0.29 \n",
        "        std_cal_focal_length = 972\n",
        "\n",
        "        fov_angle = np.degrees(np.arctan(std_img_size * std_cal_mm_per_pxl / std_cal_focal_length))\n",
        "        # for render images\n",
        "        cameras = OpenGLPerspectiveCameras(device=self.device, fov=fov_angle)\n",
        "        blend_params = BlendParams(1e-4, 1e-4, (0, 0, 0))\n",
        "        raster_settings = RasterizationSettings(\n",
        "            image_size=self.img_size, blur_radius=0.0, faces_per_pixel=1, bin_size=0\n",
        "        )\n",
        "        rasterizer = MeshRasterizer(cameras=cameras, raster_settings=raster_settings)\n",
        "        lights = PointLights(\n",
        "            device=self.device,\n",
        "            location=((0.0, 1.0, 0.0),),\n",
        "            ambient_color=((1.0, 0.0, 0.0),),\n",
        "            diffuse_color=((0.0, 0.0, 0.0),),\n",
        "            specular_color=((0.0, 0.0, 0.0),),\n",
        "        )\n",
        "        materials = Materials(\n",
        "            ambient_color=((1, 1, 1),),\n",
        "            diffuse_color=((1, 1, 1),),\n",
        "            specular_color=((1, 1, 1),),\n",
        "            shininess=0,\n",
        "            device=self.device,\n",
        "        )\n",
        "        shader = HardPhongShader(\n",
        "            lights=lights,\n",
        "            cameras=cameras,\n",
        "            materials=materials,\n",
        "            blend_params=blend_params,\n",
        "        )\n",
        "        self.phong_renderer = MeshRenderer(rasterizer=rasterizer, shader=shader)\n",
        "        # for silhouette images\n",
        "        self.silhouette_renderer = MeshRenderer(\n",
        "            rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
        "            shader=SoftSilhouetteShader(blend_params=blend_params),\n",
        "        ) # parameters to change!!!\n",
        "\n",
        "    def mesh_from_stl(self, stl):\n",
        "        # Load the stl and ignore the textures and materials.\n",
        "        stl = Mesh.from_file(Path(stl))\n",
        "        verts = torch.from_numpy(np.reshape(stl.vectors, (-1, 3)))\n",
        "        assert verts.shape[0] % 3 == 0\n",
        "        faces = torch.Tensor([[i * 3, i * 3 + 1, i * 3 + 2] for i in range(verts.shape[0] // 3)])\n",
        "        # Initialize each vertex to be white in color.\n",
        "        verts_rgb = torch.ones_like(verts)[None]  # (1, V, 3)\n",
        "        textures = TexturesVertex(verts_features=verts_rgb)\n",
        "        implant_mesh = Meshes(verts=[verts.to(self.device)], faces=[faces.to(self.device)], textures=textures.to(self.device))\n",
        "        return implant_mesh\n",
        "    \n",
        "    def join_meshes(self, femur_stl, tibia_stl):\n",
        "        # Load the stl and ignore the textures and materials.\n",
        "        femur_stl = Mesh.from_file(Path(femur_stl))\n",
        "        femur_verts = torch.from_numpy(np.reshape(femur_stl.vectors, (-1, 3)))\n",
        "        assert femur_verts.shape[0] % 3 == 0\n",
        "        femur_faces = torch.Tensor([[i * 3, i * 3 + 1, i * 3 + 2] for i in range(femur_verts.shape[0] // 3)])\n",
        "        # Initialize each vertex to be white in color.\n",
        "        femur_verts_rgb = torch.ones_like(femur_verts)[None]  # (1, V, 3)\n",
        "        #femur_textures = TexturesVertex(femur_verts_features=femur_verts_rgb)\n",
        "        \n",
        "        # Load the stl and ignore the textures and materials.\n",
        "        tibia_stl = Mesh.from_file(Path(tibia_stl))\n",
        "        tibia_verts = torch.from_numpy(np.reshape(tibia_stl.vectors, (-1, 3)))\n",
        "        assert femur_verts.shape[0] % 3 == 0\n",
        "        tibia_faces = torch.Tensor([[i * 3, i * 3 + 1, i * 3 + 2] for i in range(tibia_verts.shape[0] // 3)])\n",
        "        # Initialize each vertex to be white in color.\n",
        "        tibia_verts_rgb = torch.ones_like(tibia_verts)[None]  # (1, V, 3)\n",
        "        #tibia_textures = TexturesVertex(tibia_verts_features=tibia_verts_rgb)\n",
        "        \n",
        "        # verts = torch.Tensor(np.concatenate((femur_verts, tibia_verts), axis=0))\n",
        "        # faces = torch.Tensor(np.concatenate((femur_verts, tibia_verts), axis=0))\n",
        "        # verts_rgb = np.concatenate((femur_verts_rgb, tibia_verts_rgb), axis=1)\n",
        "        verts = torch.cat((femur_verts, tibia_verts), axis=0)\n",
        "        faces = torch.cat((femur_verts, tibia_verts), axis=0)\n",
        "        verts_rgb = torch.cat((femur_verts_rgb, tibia_verts_rgb), axis=1)\n",
        "        textures = TexturesVertex(verts_features= torch.Tensor(verts_rgb))\n",
        "        \n",
        "        implant_mesh_joined = Meshes(verts=[verts.to(self.device)], faces=[faces.to(self.device)], textures=textures.to(self.device))\n",
        "        return implant_mesh_joined\n",
        "\n",
        "    def scene_snapshot(\n",
        "        self,\n",
        "        femur_stls,\n",
        "        tibia_stls,\n",
        "        femur_R: torch.Tensor,\n",
        "        femur_T: torch.Tensor,\n",
        "        tibia_R: torch.Tensor,\n",
        "        tibia_T: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"for batch_size N\n",
        "        femur_stl, tibia_stl: string/path list of length N\n",
        "        femur_r, tibia_r: (N, 3, 3), same as `deepautomatch.viewer´\n",
        "        femur_T, tibia_T: (N, 3), same as `deepautomatch.viewer´\n",
        "\n",
        "        Note that pytorch3D has a different coordinate convention from openGl\n",
        "        (and thus flumatch and viewer.py) so that we need to change some things\n",
        "        \"\"\"\n",
        "        if not isinstance(femur_stls, list):\n",
        "            # just one string given, for would loop over characters\n",
        "            femur_stls = [femur_stls]\n",
        "        if not isinstance(tibia_stls, list):\n",
        "            tibia_stls = [tibia_stls]\n",
        "        femur_meshes = []\n",
        "        tibia_meshes = []\n",
        "        for stl in femur_stls:\n",
        "            femur_meshes.append(self.mesh_from_stl(stl))\n",
        "        for stl in tibia_stls:\n",
        "            tibia_meshes.append(self.mesh_from_stl(stl))\n",
        "\n",
        "        femur_meshes = join_meshes_as_batch(femur_meshes)\n",
        "        tibia_meshes = join_meshes_as_batch(tibia_meshes)\n",
        "\n",
        "        # adjust for differences in coordinate conventions\n",
        "        m = torch.Tensor([[-1, 0, 0], [0, 1, 0], [0, 0, -1]]).to(femur_R.device)\n",
        "        femur_T = torch.matmul(femur_T, m)\n",
        "        tibia_T = torch.matmul(tibia_T, m)\n",
        "        femur_R = femur_R.permute(0, 2, 1)\n",
        "        tibia_R = tibia_R.permute(0, 2, 1)\n",
        "        femur_R = torch.matmul(femur_R, m)\n",
        "        tibia_R = torch.matmul(tibia_R, m)\n",
        "\n",
        "        femur_imgs = self.phong_renderer(\n",
        "            meshes_world=femur_meshes, R=femur_R.to(self.device), T=femur_T.to(self.device)\n",
        "        )\n",
        "        # get rid of alpha channel\n",
        "        femur_imgs = femur_imgs[..., :3]\n",
        "        tibia_imgs = self.phong_renderer(\n",
        "            meshes_world=tibia_meshes, R=tibia_R.to(self.device), T=tibia_T.to(self.device)\n",
        "        )\n",
        "        tibia_imgs = tibia_imgs[..., :3]\n",
        "        # combine the femur_img with its tibia_img\n",
        "        combined = torch.max(femur_imgs, tibia_imgs)\n",
        "        if torch.isnan(combined).any():\n",
        "            logging.error(\"NaN encountered during creating scene snapshot\")\n",
        "        return combined\n",
        "\n",
        "    def scene_snapshot_shadow(\n",
        "        self,\n",
        "        femur_stls,\n",
        "        tibia_stls,\n",
        "        femur_R: torch.Tensor,\n",
        "        femur_T: torch.Tensor,\n",
        "        tibia_R: torch.Tensor,\n",
        "        tibia_T: torch.Tensor,\n",
        "        threshold: float = 0.5,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"same as scene snapshot, but collapse all channels\n",
        "        returns (batch_nr, img_size, img_size, 1)\"\"\"\n",
        "        # returns (batch_nr, img_size, img_size)\n",
        "        img = self.scene_snapshot(femur_stls, tibia_stls, femur_R, femur_T, tibia_R, tibia_T)\n",
        "        # collapse all 3 channels\n",
        "        img = img.sum(dim=3)\n",
        "        assert img.shape == (femur_R.shape[0], self.img_size, self.img_size)\n",
        "        img = img / img.max() \n",
        "        return img\n",
        "\n",
        "    def scene_snapshot_one_component(\n",
        "        self,\n",
        "        stls,\n",
        "        R: torch.Tensor,\n",
        "        T: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"for batch_size N\n",
        "        femur_stl, tibia_stl: string/path list of length N\n",
        "        femur_r, tibia_r: (N, 3, 3), same as `deepautomatch.viewer´\n",
        "        femur_T, tibia_T: (N, 3), same as `deepautomatch.viewer´\n",
        "\n",
        "        Note that pytorch3D has a different coordinate convention from openGl\n",
        "        (and thus flumatch and viewer.py) so that we need to change some things\n",
        "        \"\"\"\n",
        "        if not isinstance(stls, list):\n",
        "            # just one string given, for would loop over characters\n",
        "            stls = [stls]\n",
        "    \n",
        "        meshes = []\n",
        "   \n",
        "        for stl in stls:\n",
        "            meshes.append(self.mesh_from_stl(stl))\n",
        "\n",
        "        meshes = join_meshes_as_batch(meshes)\n",
        "        \n",
        "        # adjust for differences in coordinate conventions\n",
        "        m = torch.Tensor([[-1, 0, 0], [0, 1, 0], [0, 0, -1]]).to(R.device)\n",
        "        T = torch.matmul(T, m)\n",
        "        R = R.permute(0, 2, 1)\n",
        "        R = torch.matmul(R, m)\n",
        "\n",
        "        imgs = self.phong_renderer(\n",
        "            meshes_world=meshes, R=R.to(self.device), T=T.to(self.device)\n",
        "        )\n",
        "        # get rid of alpha channel\n",
        "        imgs1 = imgs[..., :3]\n",
        "        \n",
        "        return imgs1\n",
        "    \n",
        "    def scene_snapshot_shadow_one_component(\n",
        "        self,\n",
        "        stls,\n",
        "        R: torch.Tensor,\n",
        "        T: torch.Tensor,\n",
        "        threshold: float = 0.5,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"same as scene snapshot, but collapse all channels\n",
        "        returns (batch_nr, img_size, img_size, 1)\"\"\"\n",
        "        # returns (batch_nr, img_size, img_size)\n",
        "        img = self.scene_snapshot_one_component(stls, R, T)\n",
        "        # collapse all 3 channels\n",
        "        img = img.sum(dim=3)\n",
        "        assert img.shape == (R.shape[0], self.img_size, self.img_size)\n",
        "        img = img / img.max() \n",
        "        return img\n",
        "\n",
        "def create_ground_truth(index):\n",
        "    device = torch.device(\"cpu\")\n",
        "    viewer = Pytorch3dViewer(200, device=device)\n",
        "    d = Path(\"./data_files/stl_3D_models\")\n",
        "    femur_stls = [d / \"cr_fem_4_r_narrow_mm.stl\"]\n",
        "    tibia_stls = [d / \"cr_tib_modular_3_r_narrow.stl\"]\n",
        "    # create list \n",
        "    data_folder = \"./data_files/csv_files/flumatch_data.csv\"\n",
        "    f = open(data_folder)\n",
        "    load_data_info = pd.read_csv(f)\n",
        "    \n",
        "    reference_list = []\n",
        "    \n",
        "    for i in range(index):\n",
        "        \n",
        "        poses = {\n",
        "            \"femur_rx\": [load_data_info['femur_rx'][i]],\n",
        "            \"femur_ry\": [load_data_info['femur_ry'][i]],\n",
        "            \"femur_rz\": [load_data_info['femur_rz'][i]],\n",
        "            \"femur_tx\": [load_data_info['femur_tx'][i]],\n",
        "            \"femur_ty\": [load_data_info['femur_ty'][i]],\n",
        "            \"femur_tz\": [load_data_info['femur_tz'][i]],\n",
        "            \"tibia_rx\": [load_data_info['tibia_rx'][i]],\n",
        "            \"tibia_ry\": [load_data_info['tibia_ry'][i]],\n",
        "            \"tibia_rz\": [load_data_info['tibia_ry'][i]],\n",
        "            \"tibia_tx\": [load_data_info['tibia_tx'][i]],\n",
        "            \"tibia_ty\": [load_data_info['tibia_ty'][i]],\n",
        "            \"tibia_tz\": [load_data_info['tibia_tz'][i]],\n",
        "        }\n",
        "    \n",
        "        for k, v in poses.items():\n",
        "            poses[k] = torch.Tensor(v)\n",
        "        mm_per_pxl = 0.2876\n",
        "        femur_R = rotation_matrix_from_euler(\n",
        "            poses[\"femur_rx\"], poses[\"femur_ry\"], poses[\"femur_rz\"]\n",
        "        )\n",
        "        tibia_R = rotation_matrix_from_euler(\n",
        "            poses[\"tibia_rx\"], poses[\"tibia_ry\"], poses[\"tibia_rz\"]\n",
        "        )\n",
        "        \"\"\" for later refactoring of rotation.py\n",
        "        eulers = torch.cat([poses[\"femur_rz\"], poses[\"femur_rx\"], poses[\"femur_ry\"]]).T * np.pi/180\n",
        "        femur_R_2 = transforms.euler_angles_to_matrix(eulers, \"ZXY\")\n",
        "        print(femur_R)\n",
        "        print(femur_R_2)\n",
        "        \"\"\"\n",
        "        \n",
        "        femur_T = torch.cat(\n",
        "            [torch.unsqueeze(v, dim=0) for v in [poses[\"femur_tx\"], poses[\"femur_ty\"], poses[\"femur_tz\"]]]\n",
        "        ).T\n",
        "        tibia_T = torch.cat(\n",
        "            [torch.unsqueeze(v, dim=0) for v in [poses[\"tibia_tx\"], poses[\"tibia_ty\"], poses[\"tibia_tz\"]]]\n",
        "        ).T\n",
        "        py3d_imgs_shadow = viewer.scene_snapshot_shadow(\n",
        "            femur_stls, tibia_stls, femur_R, femur_T, tibia_R, tibia_T\n",
        "        )\n",
        "        py3d_imgs_shadow = py3d_imgs_shadow.cpu().numpy()\n",
        "        reference_list.append(py3d_imgs_shadow[0].squeeze())\n",
        "    \n",
        "    return reference_list\n",
        "\n",
        "def create_ground_truth_one_component(index, component ='tibia'):\n",
        "    device = torch.device(\"cpu\")\n",
        "    viewer = Pytorch3dViewer(200, device=device)\n",
        "    d = Path(\"./data_files/stl_3D_models\")\n",
        "    femur_stls = [d / \"cr_fem_4_r_narrow_mm.stl\"]\n",
        "    tibia_stls = [d / \"cr_tib_modular_3_r_narrow.stl\"]\n",
        "\n",
        "    # create list \n",
        "    data_folder = \"./data_files/csv_files/flumatch_data.csv\"\n",
        "    f = open(data_folder)\n",
        "    load_data_info = pd.read_csv(f)\n",
        "    \n",
        "    reference_list = []\n",
        "    \n",
        "    if component == 'tibia':\n",
        "        for i in range(index):\n",
        "            \n",
        "            poses = {\n",
        "                \"tibia_rx\": [load_data_info['tibia_rx'][i]],\n",
        "                \"tibia_ry\": [load_data_info['tibia_ry'][i]],\n",
        "                \"tibia_rz\": [load_data_info['tibia_ry'][i]],\n",
        "                \"tibia_tx\": [load_data_info['tibia_tx'][i]],\n",
        "                \"tibia_ty\": [load_data_info['tibia_ty'][i]],\n",
        "                \"tibia_tz\": [load_data_info['tibia_tz'][i]],\n",
        "            }\n",
        "        \n",
        "            for k, v in poses.items():\n",
        "                poses[k] = torch.Tensor(v)\n",
        "            \n",
        "            mm_per_pxl = 0.2876\n",
        "            \n",
        "            tibia_R = rotation_matrix_from_euler(\n",
        "                poses[\"tibia_rx\"], poses[\"tibia_ry\"], poses[\"tibia_rz\"]\n",
        "            )\n",
        "            \"\"\" for later refactoring of rotation.py\n",
        "            eulers = torch.cat([poses[\"femur_rz\"], poses[\"femur_rx\"], poses[\"femur_ry\"]]).T * np.pi/180\n",
        "            femur_R_2 = transforms.euler_angles_to_matrix(eulers, \"ZXY\")\n",
        "            print(femur_R)\n",
        "            print(femur_R_2)\n",
        "            \"\"\"\n",
        "            \n",
        "            tibia_T = torch.cat(\n",
        "                [torch.unsqueeze(v, dim=0) for v in [poses[\"tibia_tx\"], poses[\"tibia_ty\"], poses[\"tibia_tz\"]]]\n",
        "            ).T\n",
        "            py3d_imgs_shadow = viewer.scene_snapshot_shadow_one_component(tibia_stls, tibia_R, tibia_T)\n",
        "            py3d_imgs_shadow = py3d_imgs_shadow.cpu().numpy()\n",
        "            reference_list.append(py3d_imgs_shadow[0].squeeze())\n",
        "        \n",
        "    elif component == 'femur':\n",
        "        for i in range(index):\n",
        "            \n",
        "            poses = {\n",
        "                \"femur_rx\": [load_data_info['femur_rx'][i]],\n",
        "                \"femur_ry\": [load_data_info['femur_ry'][i]],\n",
        "                \"femur_rz\": [load_data_info['femur_rz'][i]],\n",
        "                \"femur_tx\": [load_data_info['femur_tx'][i]],\n",
        "                \"femur_ty\": [load_data_info['femur_ty'][i]],\n",
        "                \"femur_tz\": [load_data_info['femur_tz'][i]],\n",
        "                }\n",
        "            \n",
        "            for k, v in poses.items():\n",
        "                poses[k] = torch.Tensor(v)\n",
        "                \n",
        "            mm_per_pxl = 0.2876\n",
        "            femur_R = rotation_matrix_from_euler(\n",
        "                poses[\"femur_rx\"], poses[\"femur_ry\"], poses[\"femur_rz\"]\n",
        "            )\n",
        "            femur_T = torch.cat(\n",
        "                [torch.unsqueeze(v, dim=0) for v in [poses[\"femur_tx\"], poses[\"femur_ty\"], poses[\"femur_tz\"]]]\n",
        "            ).T\n",
        "            py3d_imgs_shadow = viewer.scene_snapshot_shadow_one_component(femur_stls, femur_R, femur_T)\n",
        "            py3d_imgs_shadow = py3d_imgs_shadow.cpu().numpy()\n",
        "            reference_list.append(py3d_imgs_shadow[0].squeeze())\n",
        "    \n",
        "    return reference_list \n",
        "\n",
        "def create_blurred_shadows(index):\n",
        "    device = torch.device(\"cpu\")\n",
        "    # reference_list = create_ground_truth(index=1)\n",
        "    blurred_list = []\n",
        "    for a in reference_list:\n",
        "        blurred = gaussian_filter(a, sigma=0.5)\n",
        "        blurred_list.append(blurred)\n",
        "    return blurred_list\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, meshes, renderer, phong_renderer, image_ref, device=None):\n",
        "        super().__init__()\n",
        "        if device is None:\n",
        "            self.device = torch.device(\"cuda:0\")\n",
        "        else:\n",
        "            self.device = torch.device(\"cpu\")\n",
        "        self.meshes = meshes\n",
        "        self.renderer = renderer\n",
        "        self.phong_renderer = phong_renderer\n",
        "        # self.image_ref = image_ref\n",
        "        \n",
        "        #Get the silhouette of the reference image by finding all non-black pixel values. \n",
        "        # image_ref = torch.from_numpy((image_ref[..., :3].max(-1) != 1).astype(np.float32))\n",
        "        # self.register_buffer('image_ref', image_ref)\n",
        "        \n",
        "        data_folder = \"./data_files/csv_files/flumatch_data.csv\"\n",
        "        f = open(data_folder)\n",
        "        load_data_info = pd.read_csv(f)\n",
        "        viewer = Pytorch3dViewer(200, device=device)\n",
        "\n",
        "        poses = {\n",
        "                \"femur_rx\": [load_data_info['femur_rx'][0]],\n",
        "                \"femur_ry\": [load_data_info['femur_ry'][0]],\n",
        "                \"femur_rz\": [load_data_info['femur_rz'][0]],\n",
        "                \"femur_tx\": [load_data_info['femur_tx'][0]+5],\n",
        "                \"femur_ty\": [load_data_info['femur_ty'][0]+5],\n",
        "                \"femur_tz\": [load_data_info['femur_tz'][0]+5],\n",
        "                }\n",
        "            \n",
        "        for k, v in poses.items():\n",
        "            poses[k] = torch.Tensor(v) \n",
        "        #mm_per_pxl = 0.2876\n",
        "        self.R = rotation_matrix_from_euler(\n",
        "            poses[\"femur_rx\"], poses[\"femur_ry\"], poses[\"femur_rz\"])\n",
        "        self.T = torch.cat(\n",
        "            [torch.unsqueeze(v, dim=0) for v in [poses[\"femur_tx\"], poses[\"femur_ty\"], poses[\"femur_tz\"]]]\n",
        "        ).T\n",
        "\n",
        "        self.m = torch.Tensor([[-1, 0, 0], [0, 1, 0], [0, 0, -1]]).to(self.R.device)\n",
        "        self.T = torch.matmul(self.T, self.m)\n",
        "        self.R = self.R.permute(0, 2, 1)\n",
        "        self.R = torch.matmul(self.R, self.m)\n",
        "       \n",
        "        # Parameters to optimise\n",
        "        self.R = nn.Parameter(self.R.to(self.device))\n",
        "        self.T = nn.Parameter(self.T.to(self.device))\n",
        "        \n",
        "        # Reference \n",
        "        \n",
        "        poses_ref = {\n",
        "             \"femur_rx\": [load_data_info['femur_rx'][0]],\n",
        "             \"femur_ry\": [load_data_info['femur_ry'][0]],\n",
        "             \"femur_rz\": [load_data_info['femur_rz'][0]],\n",
        "             \"femur_tx\": [load_data_info['femur_tx'][0]],\n",
        "             \"femur_ty\": [load_data_info['femur_ty'][0]],\n",
        "             \"femur_tz\": [load_data_info['femur_tz'][0]],\n",
        "             }\n",
        "            \n",
        "        for k, v in poses_ref.items():\n",
        "            poses_ref[k] = torch.Tensor(v) \n",
        "        #mm_per_pxl = 0.2876\n",
        "        self.R_ref = rotation_matrix_from_euler(\n",
        "            poses_ref[\"femur_rx\"], poses_ref[\"femur_ry\"], poses_ref[\"femur_rz\"])\n",
        "        self.T_ref = torch.cat(\n",
        "            [torch.unsqueeze(v, dim=0) for v in [poses_ref[\"femur_tx\"], poses_ref[\"femur_ty\"], poses_ref[\"femur_tz\"]]]\n",
        "        ).T\n",
        "        \n",
        "        # py3d_imgs_shadow = viewer.scene_snapshot_shadow_one_component(femur_stls, femur_R, femur_T)\n",
        "        # py3d_imgs_shadow = py3d_imgs_shadow.cpu().numpy()\n",
        "        self.m_ref = torch.Tensor([[-1, 0, 0], [0, 1, 0], [0, 0, -1]]).to(self.R_ref.device)\n",
        "        self.T_ref = torch.matmul(self.T_ref, self.m_ref)\n",
        "        self.R_ref = self.R_ref.permute(0, 2, 1)\n",
        "        self.R_ref = torch.matmul(self.R_ref, self.m_ref)\n",
        "        self.image_ref = self.renderer(meshes_world=self.meshes, R=self.R_ref, T=self.T_ref)\n",
        "    \n",
        "    def forward(self):\n",
        "\n",
        "        # print(type(self.offset_R))\n",
        "        image1 = self.renderer(meshes_world=self.meshes, R=self.R, T=self.T)\n",
        "        # image1 = image1.detach().squeeze().cpu().numpy()\n",
        "        # image1[image1!=0] = 1\n",
        "        image_ref = self.image_ref\n",
        "        \n",
        "        # Calculate the silhouette loss\n",
        "        loss_j = JaccardLoss()\n",
        "        loss = loss_j.forward(pred = image1, target = self.image_ref)\n",
        "        \n",
        "        # loss = torch.sum((image1 - self.image_ref) ** 2)\n",
        "        # loss = torch.sum((image1[...,3] - self.image_ref) ** 2)\n",
        "        \n",
        "        return loss, image1, image_ref\n",
        "    \n",
        "def rescale_array(image):\n",
        "    rescale = 2.*(image - np.min(image))/np.ptp(image)-1\n",
        "    change = np.int8(rescale)\n",
        "    return rescale    \n",
        "    \n",
        "def optimisation():\n",
        "    device = torch.device(\"cpu\")\n",
        "    # blurred_list = create_blurred_shadows(index=1)\n",
        "    reference_list =  create_ground_truth_one_component(index=1, component ='femur')\n",
        "    d = Path(\"./data_files/stl_3D_models\")\n",
        "    femur_stls = [d / \"cr_fem_4_r_narrow_mm.stl\"]\n",
        "    tibia_stls = [d / \"cr_tib_modular_3_r_narrow.stl\"]\n",
        "    viewer = Pytorch3dViewer(200, device=device)\n",
        "    \n",
        "    #for b in blurred_list:\n",
        "    for ref_img in reference_list:\n",
        "        plt.figure()\n",
        "        plt.grid(False)\n",
        "        plt.imshow(ref_img)\n",
        "       \n",
        "        # # Initialize a model using the renderer, mesh and reference image\n",
        "        ref_img[ref_img!=1] = 0\n",
        "        model1 = Model(viewer.mesh_from_stl(femur_stls[0]),viewer.silhouette_renderer, viewer.phong_renderer, ref_img, device=device)\n",
        "        optimizer = torch.optim.Adam(model1.parameters(), lr=0.05) #change?\n",
        "        \n",
        "        plt.figure(figsize=(10, 10))\n",
        "        _, image_init, image_ref = model1()\n",
        "        image_start = image_init.detach().squeeze().cpu().numpy()[..., 3]\n",
        "        image_start[image_start!=0] = 1\n",
        "       \n",
        "        plt.subplot(1, 2, 1)\n",
        "        # plt.imshow(image_init, cmap=\"gray\")\n",
        "        plt.imshow(image_start, cmap=\"gray\")\n",
        "        plt.grid(False)\n",
        "        plt.title(\"Starting position\")\n",
        "        \n",
        "        image_new_ref = model1.image_ref\n",
        "        image_new_ref = image_new_ref.detach().squeeze().cpu().numpy()[..., 3]\n",
        "        image_new_ref[image_new_ref!=0] = 1\n",
        "        \n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(image_new_ref, cmap=\"gray\")\n",
        "        plt.grid(False)\n",
        "        plt.title(\"Reference silhouette\");\n",
        "       \n",
        "        # Optimisation loop\n",
        "        loss_list = []\n",
        "        iterations = range(1000)\n",
        "        \n",
        "        for i in iterations: # change number\n",
        "            print(i)\n",
        "            optimizer.zero_grad()\n",
        "            loss, _, _ = model1()  \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # if loss.item() < 100: \n",
        "            #     break\n",
        "            # if i % 10 == 0:\n",
        "            image = viewer.phong_renderer(meshes_world=model1.meshes.clone(), R=model1.R, T=model1.T)\n",
        "            image = image[0, ..., :3].detach().squeeze().cpu().numpy()\n",
        "            # image = rescale_array(image)\n",
        "            image[image!=0] = 1\n",
        "            # image = img_as_ubyte(image)\n",
        "            loss_list.append(loss.data)\n",
        "            \n",
        "        plt.figure()\n",
        "        plt.imshow(rgb2gray(image), cmap='gray')\n",
        "        plt.title(\"iter: %d, loss: %0.2f\" % (i, loss.data))\n",
        "        plt.grid(\"off\")\n",
        "        plt.axis(\"off\")\n",
        "            \n",
        "        plt.figure()\n",
        "        plt.plot(iterations, loss_list)\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylabel('Jaccard Loss')\n",
        "        plt.title(\"Loss VS iterations\")\n",
        "       \n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cpu\")\n",
        "    optimisation()\n",
        "     \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}